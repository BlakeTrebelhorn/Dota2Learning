{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Statements and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier as MLPC\n",
    "from sklearn.naive_bayes import GaussianNB as GNB\n",
    "from sklearn.naive_bayes import BernoulliNB as BNB\n",
    "from sklearn.naive_bayes import MultinomialNB as MNB\n",
    "from sklearn.preprocessing import MinMaxScaler as MMS\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNC\n",
    "from sklearn.model_selection import GridSearchCV as GSCV\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.ensemble import AdaBoostClassifier as ABC\n",
    "from sklearn.linear_model import SGDClassifier as SGDC\n",
    "\n",
    "\n",
    "dota_data = pandas.read_csv('dota2Train.csv', header = None)\n",
    "data = dota_data.iloc[:,1:]\n",
    "target = dota_data.iloc[:,0]\n",
    "(training_data, validation_data, training_target, validation_target) = tts(data, target, test_size = .15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       ..., \n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1]], dtype=int64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mms = MMS()\n",
    "training_data_temp = mms.fit_transform(training_data)\n",
    "validation_data_temp = mms.fit_transform(validation_data)\n",
    "# training_target_temp = mms.fit_transform(training_target)\n",
    "# validation_target_temp = mms.fit_transform(validation_target)\n",
    "\n",
    "training_data_mms = pandas.DataFrame(data=training_data_temp[:,:])\n",
    "validation_data_mms = pandas.DataFrame(data=validation_data_temp[:,:])\n",
    "training_target_mms = training_target.reshape(-1,1)\n",
    "validation_target_mms = validation_target.reshape(-1,1)\n",
    "# training_target_mms = pandas.DataFrame(data=training_target_temp[:,:])\n",
    "# validation_target_mms = pandas.DataFrame(data=validation_target_temp[:,:])\n",
    "training_target_mms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# http://stackoverflow.com/questions/32857029/python-scikit-learn-pca-explained-variance-ratio-cutoff\n",
    "pca = PCA(n_components=10, whiten=True)\n",
    "pca.fit(training_data)\n",
    "# print(pca.explained_variance_)\n",
    "# print(pca.explained_variance_ratio_)\n",
    "# print(pca.explained_variance_ratio_.cumsum())\n",
    "\n",
    "training_data_temp2 = pca.transform(training_data)\n",
    "validation_data_temp2 = pca.transform(validation_data)\n",
    "\n",
    "training_data_pca = pandas.DataFrame(data=training_data_temp2[:,:])\n",
    "validation_data_pca = pandas.DataFrame(data=validation_data_temp2[:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.569146639804\n"
     ]
    }
   ],
   "source": [
    "rfc = RFC(n_jobs=-1, n_estimators=100, max_features=0.5)\n",
    "rfc.fit(training_data,training_target)\n",
    "rfc_pred = rfc.predict(validation_data)\n",
    "print(acc(rfc_pred, validation_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.467045618075\n"
     ]
    }
   ],
   "source": [
    "perc = Perceptron(n_jobs=-1, n_iter=1001,eta0=0.1)\n",
    "perc.fit(training_data,training_target)\n",
    "perc_pred = perc.predict(validation_data)\n",
    "print(acc(perc_pred, validation_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.596272845014\n"
     ]
    }
   ],
   "source": [
    "mlpc = MLPC(hidden_layer_sizes=(115,115,115,115,115,115), activation='tanh', max_iter=500)\n",
    "mlpc.fit(training_data,training_target)\n",
    "mlpc_pred = mlpc.predict(validation_data)\n",
    "print(acc(mlpc_pred, validation_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.573104043747\n"
     ]
    }
   ],
   "source": [
    "bnb = BNB()\n",
    "bnb.fit(training_data,training_target)\n",
    "bnb_pred = bnb.predict(validation_data)\n",
    "print(acc(bnb_pred, validation_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.553101165635\n"
     ]
    }
   ],
   "source": [
    "gnb = GNB()\n",
    "gnb.fit(training_data,training_target)\n",
    "gnb_pred = gnb.predict(validation_data)\n",
    "print(acc(gnb_pred, validation_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.535041013095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\program files\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "mnb = MNB()\n",
    "mnb.fit(training_data_mms,training_target_mms)\n",
    "mnb_pred = mnb.predict(validation_data_mms)\n",
    "print(acc(mnb_pred, validation_target_mms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training took 978.3524339199066 seconds ---\n",
      "0.583393293999\n",
      "--- 1071.2892246246338 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "svc = SVC(C=0.25)\n",
    "svc.fit(training_data,training_target)\n",
    "print(\"--- Training took %s seconds ---\" % (time.time() - start_time))\n",
    "svc_pred = svc.predict(validation_data)\n",
    "print(acc(svc_pred, validation_target))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training took 1085.9452102184296 seconds ---\n",
      "0.519715066916\n",
      "--- Total time: 1223.8227014541626 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "sigmoid_svc = SVC(kernel='sigmoid')\n",
    "sigmoid_svc.fit(training_data,training_target)\n",
    "print(\"--- Training took %s seconds ---\" % (time.time() - start_time))\n",
    "sigmoid_svc_pred = sigmoid_svc.predict(validation_data)\n",
    "print(acc(sigmoid_svc_pred, validation_target))\n",
    "print(\"--- Total time: %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training took 1164.3281786441803 seconds ---\n",
      "0.603396172111\n",
      "--- Total time: 1243.3781158924103 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "linear_svc = SVC(kernel='linear', C=0.05)\n",
    "linear_svc.fit(training_data,training_target)\n",
    "print(\"--- Training took %s seconds ---\" % (time.time() - start_time))\n",
    "linear_svc_pred = linear_svc.predict(validation_data)\n",
    "print(acc(linear_svc_pred, validation_target))\n",
    "print(\"--- Total time: %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dumping linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['linear_svc_c0.05.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# joblib.dump(linear_svc, 'linear_svc_c0.05.pkl')\n",
    "# linear_svc = joblib.load('linear_svc.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training took 1408.5175392627716 seconds ---\n",
      "0.598215570586\n",
      "--- Total time: 1489.2745802402496 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "poly_svc = SVC(kernel='poly', C=0.1, degree=2, gamma=0.005)\n",
    "# print(poly_svc.get_params())\n",
    "poly_svc.fit(training_data,training_target)\n",
    "print(\"--- Training took %s seconds ---\" % (time.time() - start_time))\n",
    "poly_svc_pred = poly_svc.predict(validation_data)\n",
    "print(acc(poly_svc_pred, validation_target))\n",
    "print(\"--- Total time: %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dumping poly kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['poly_svc_d2_g.005_c.1.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(poly_svc, 'poly_svc_d2_g.005_c.1.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with PCA data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training took 121.50322651863098 seconds ---\n",
      "0.529500647575\n",
      "--- Total time: 129.50003266334534 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "lin_svc_pca = SVC(kernel='linear', C=0.1, gamma=0.001)\n",
    "lin_svc_pca.fit(training_data_pca,training_target_for_pca)\n",
    "print(\"--- Training took %s seconds ---\" % (time.time() - start_time))\n",
    "lin_svc_pred_pca = lin_svc_pca.predict(validation_data_pca)\n",
    "print(acc(lin_svc_pred_pca, validation_target_for_pca))\n",
    "print(\"--- Total time: %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poly SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training took 157.09088730812073 seconds ---\n",
      "0.529500647575\n",
      "--- Total time: 167.30319595336914 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "poly_svc_pca = SVC(kernel='poly', degree=2, C=0.1, gamma=0.001)\n",
    "poly_svc_pca.fit(training_data_pca,training_target_for_pca)\n",
    "print(\"--- Training took %s seconds ---\" % (time.time() - start_time))\n",
    "poly_svc_pred_pca = poly_svc_pca.predict(validation_data_pca)\n",
    "print(acc(poly_svc_pred_pca, validation_target_for_pca))\n",
    "print(\"--- Total time: %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBF SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training took 218.41278553009033 seconds ---\n",
      "0.529500647575\n",
      "--- Total time: 236.5156762599945 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "rbf_svc_pca = SVC(kernel='rbf', C=0.1, gamma=0.001)\n",
    "rbf_svc_pca.fit(training_data_pca, training_target_for_pca)\n",
    "print(\"--- Training took %s seconds ---\" % (time.time() - start_time))\n",
    "rbf_svc_pred_pca = rbf_svc_pca.predict(validation_data_pca)\n",
    "print(acc(rbf_svc_pred_pca, validation_target_for_pca))\n",
    "print(\"--- Total time: %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training took 32.70646333694458 seconds ---\n",
      "0.598287523385\n",
      "--- Total time: 32.71646428108215 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "log_reg = LR(solver='sag', max_iter=500, C=0.05)\n",
    "# log_reg = LR(C=0.05)\n",
    "log_reg.fit(training_data,training_target)\n",
    "print(\"--- Training took %s seconds ---\" % (time.time() - start_time))\n",
    "log_reg_pred = log_reg.predict(validation_data)\n",
    "print(acc(log_reg_pred, validation_target))\n",
    "print(\"--- Total time: %s seconds ---\" % (time.time() - start_time))\n",
    "# 0.598287523385, 0.598143617787"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training took 2.882268190383911 seconds ---\n",
      "0.525831054828\n",
      "--- Total time: 44.47872018814087 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "knc = KNC(weights='distance')\n",
    "knc.fit(training_data,training_target)\n",
    "print(\"--- Training took %s seconds ---\" % (time.time() - start_time))\n",
    "knc_pred = knc.predict(validation_data)\n",
    "print(acc(knc_pred, validation_target))\n",
    "print(\"--- Total time: %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading in Pickled kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lin_svc_1 = joblib.load('Pickled Kernels/linear_svc.pkl')\n",
    "lin_svc_2 = joblib.load('Pickled Kernels/linear_svc_c0.05.pkl')\n",
    "lin_svc_3 = joblib.load('Pickled Kernels/linear_svc_c0.10.pkl')\n",
    "lin_svc_4 = joblib.load('Pickled Kernels/linear_svc_c0.25.pkl')\n",
    "\n",
    "poly_svc_1 = joblib.load('Pickled Kernels/poly_svc_c0.10.pkl')\n",
    "poly_svc_2 = joblib.load('Pickled Kernels/poly_svc_c0.25.pkl')\n",
    "poly_svc_3 = joblib.load('Pickled Kernels/poly_svc_c0.10_d2.pkl')\n",
    "poly_svc_4 = joblib.load('Pickled Kernels/poly_svc_d2_g.001_c.1.pkl')\n",
    "poly_svc_5 = joblib.load('Pickled Kernels/poly_svc_d2_g.005_c.1.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting and testing pickled kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC 2: 0.60210102173\n",
      "Linear SVC 3: 0.601885163333\n",
      "Linear SVC 4: 0.60210102173\n",
      "Polynomial SVC 3: 0.601165635343\n",
      "Polynomial SVC 4: 0.600158296158\n"
     ]
    }
   ],
   "source": [
    "# l1 = lin_svc_1.predict(validation_data)\n",
    "l2 = lin_svc_2.predict(validation_data)\n",
    "l3 = lin_svc_3.predict(validation_data)\n",
    "l4 = lin_svc_4.predict(validation_data)\n",
    "\n",
    "p1 = poly_svc_1.predict(validation_data)\n",
    "p2 = poly_svc_2.predict(validation_data)\n",
    "p3 = poly_svc_3.predict(validation_data)\n",
    "p4 = poly_svc_4.predict(validation_data)\n",
    "p5 = poly_svc_5.predict(validation_data)\n",
    "\n",
    "# print('Linear SVC 1:', acc(l1, validation_target))\n",
    "print('Linear SVC 2:', acc(l2, validation_target))\n",
    "print('Linear SVC 3:', acc(l3, validation_target))\n",
    "print('Linear SVC 4:', acc(l4, validation_target))\n",
    "\n",
    "# print('Polynomial SVC 1:', acc(p1, validation_target))\n",
    "# print('Polynomial SVC 2:', acc(p2, validation_target))\n",
    "print('Polynomial SVC 3:', acc(p3, validation_target))\n",
    "print('Polynomial SVC 4:', acc(p4, validation_target))\n",
    "# print('Polynomial SVC 5:', acc(p5, validation_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search on Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 10.0\n",
      "Penalty: l2\n",
      "Solver: lbfgs\n"
     ]
    }
   ],
   "source": [
    "# log_grid = {'C':[0.1,0.01,0.001], 'penalty':['l1','l2'], 'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag']}\n",
    "# log_grid = {'C':[1.0,0.1,0.01,0.001], 'penalty':['l1','l2'], 'solver':['liblinear']}\n",
    "# log_grid = {'C':[9,10.0,11], 'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag']}\n",
    "log_grid = {'C':[9.96875,10.0,10.03125], 'solver':['lbfgs']}\n",
    "\n",
    "log_reg = GSCV(LR(max_iter=1000, n_jobs=-1), log_grid)\n",
    "log_reg.fit(training_data,training_target)\n",
    "\n",
    "print('C:',log_reg.best_estimator_.C)                    #1.0,1.0,10,10,10,10,10\n",
    "print('Penalty:',log_reg.best_estimator_.penalty)        #l1,l2,l2,l2,l2,l2,l2\n",
    "print('Solver:',log_reg.best_estimator_.solver)          #liblinear,lbfgs,lbfgs,lbfgs,lbfgs,lbfgs,lbfgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regressor Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.601597352137\n"
     ]
    }
   ],
   "source": [
    "logistic_regressor = LR(C=10,solver='lbfgs',max_iter=400,n_jobs=-1)\n",
    "logistic_regressor.fit(training_data,training_target)\n",
    "lr_pred = logistic_regressor.predict(validation_data)\n",
    "print(acc(lr_pred, validation_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search on Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.592531299468\n",
      "--- Total time: 564.4012639522552 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Here's a good resource I found on the hidden layer sizes\n",
    "# http://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw\n",
    "start_time = time.time()\n",
    "mlpc_grid = {'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam']}\n",
    "mlpc_testing = GSCV(MLPC(hidden_layer_sizes=59), mlpc_grid) #hidden layer sizes = input layer + output layer /2 (116+1 /2)\n",
    "# mlpc_testing = MLPC(activation='identity', solver='lbfgs', hidden_layer_sizes=59)\n",
    "mlpc_testing.fit(training_data,training_target)\n",
    "\n",
    "# print('Activation:',mlpc_testing.best_estimator_.activation)\n",
    "# print('Solver:',mlpc_testing.best_estimator_.solver)\n",
    "mlpc_final_pred = mlpc_testing.predict(validation_data)\n",
    "print(acc(mlpc_final_pred, validation_target))\n",
    "\n",
    "print(\"--- Total time: %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training took 0.29528331756591797 seconds ---\n",
      "0.598143617787\n",
      "--- Total time: 0.3037912845611572 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "lda = LDA(solver='lsqr')\n",
    "lda.fit(training_data,training_target)\n",
    "print(\"--- Training took %s seconds ---\" % (time.time() - start_time))\n",
    "lda_pred = lda.predict(validation_data)\n",
    "print(acc(lda_pred, validation_target))\n",
    "print(\"--- Total time: %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training took 6.566806793212891 seconds ---\n",
      "0.590012951504\n",
      "--- Total time: 6.754987716674805 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "abc = ABC(n_estimators=110)\n",
    "abc.fit(training_data,training_target)\n",
    "print(\"--- Training took %s seconds ---\" % (time.time() - start_time))\n",
    "abc_pred = abc.predict(validation_data)\n",
    "print(acc(abc_pred, validation_target))\n",
    "print(\"--- Total time: %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "sgdc = SGDC()\n",
    "sgdc.fit(training_data,training_target)\n",
    "print(\"--- Training took %s seconds ---\" % (time.time() - start_time))\n",
    "sgdc_pred = sgdc.predict(validation_data)\n",
    "print(acc(sgdc_pred, validation_target))\n",
    "print(\"--- Total time: %s seconds ---\" % (time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
